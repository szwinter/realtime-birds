{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d06e6f2-ee0b-4b30-8baf-9cc510d178bb",
   "metadata": {},
   "source": [
    "# A1. Preprocessing\n",
    "\n",
    "**INPUTS DIFFER FROM PREVIOUS VERSIONS:** Some files are renamed from what O2 sent originally. The input rasters must now have lowercase titles to be consistent with previous files. What was initially sent as `_va.tif` should be renamed to `_vaL.tif` to signify that this contains variance on the linear scale. This document computes new files denoted `_va.tif` which contain the variance on the probability scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b513512e-90e0-4cac-bf88-c0afa154c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "import pyreadr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.distributions import Normal\n",
    "import torch\n",
    "from scipy.stats import norm as scipy_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa6979-23e3-490a-a404-0ace26f408ee",
   "metadata": {},
   "source": [
    "Add basic features to `XData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0626dc84-818a-44c3-ac71-8b33c77f7713",
   "metadata": {},
   "outputs": [
    {
     "ename": "PyreadrError",
     "evalue": "File b'/scratch/project_2003104/gtikhono/bird_app/single_species/data/meta.RData' does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPyreadrError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/project_2003104/gtikhono/bird_app/single_species/data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#data_path = \"/scratch/project_2003104/gtikhono/bird_app/data/acanthis_flammea/\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[43mpyreadr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta.RData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m XData \u001b[38;5;241m=\u001b[39m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXData\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m XData[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_duration\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(XData[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyreadr/pyreadr.py:65\u001b[0m, in \u001b[0;36mread_r\u001b[0;34m(path, use_objects, timezone)\u001b[0m\n\u001b[1;32m     63\u001b[0m filename_bytes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(filename_bytes)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filename_bytes):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PyreadrError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename_bytes))\n\u001b[1;32m     66\u001b[0m parser\u001b[38;5;241m.\u001b[39mparse(filename_bytes)\n\u001b[1;32m     68\u001b[0m result \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "\u001b[0;31mPyreadrError\u001b[0m: File b'/scratch/project_2003104/gtikhono/bird_app/single_species/data/meta.RData' does not exist!"
     ]
    }
   ],
   "source": [
    "# data_path should contain meta.RData and species-specific folders with prior predictions, a_maps, and va_maps\n",
    "data_path = \"/scratch/project_2003104/gtikhono/bird_app/single_species/data/\"\n",
    "#data_path = \"/scratch/project_2003104/gtikhono/bird_app/data/acanthis_flammea/\"\n",
    "\n",
    "meta = pyreadr.read_r(data_path + \"meta.RData\")\n",
    "XData = meta[\"XData\"]\n",
    "XData[\"log_duration\"] = np.log(XData[\"duration\"]+1e-6)\n",
    "XData[\"rec_class\"] = \"\"\n",
    "XData.loc[XData[\"rec_type\"] == \"point\", \"rec_class\"] = \"fixed\"\n",
    "XData.loc[(XData[\"duration\"] <= 300)&(XData[\"rec_type\"] != \"point\"), \"rec_class\"] = \"short\"\n",
    "XData.loc[(XData[\"duration\"] > 300)&(XData[\"rec_type\"] != \"point\"), \"rec_class\"] = \"long\"\n",
    "\n",
    "print(\"Missing values:\")\n",
    "print(XData.isna().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e474069-a3a6-487e-b530-d7eea96bd741",
   "metadata": {},
   "source": [
    "Extract prior migration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2672e-8286-444e-9634-5c54c3935270",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_params = meta[\"migration.pars\"]\n",
    "index_style = dict(zip(prior_params.index, [x.lower().replace(\" \", \"_\") for x in prior_params.index]))\n",
    "prior_params.rename(index=index_style, inplace=True)\n",
    "with open(data_path + \"migration_prior_params.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(prior_params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114feae-ab36-424b-b5ce-855b2a1a9e4e",
   "metadata": {},
   "source": [
    "Load a single species and perform basic feature engineerng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130337d-176e-47a6-b207-d007a02dcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = \"Turdus merula\"\n",
    "sp_lower = sp.lower().replace(\" \", \"_\").split(\".\")[0]\n",
    "sp_dir = data_path + sp_lower + \"/\"\n",
    "species_raw = pyreadr.read_r(sp_dir + sp + \"_prior.RData\")\n",
    "species = pd.concat([species_raw[k] for k in species_raw.keys()], axis=1)\n",
    "species[\"complete\"] = species.isna().sum(axis=1) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f6ce9-8d64-4cd1-9640-da32df8202ad",
   "metadata": {},
   "source": [
    "Extract different sets of training data (e.g., all data from 2023) and all data from Helsinki. Make sure the extracted XData data is in the same order as the species data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f57160-7896-4afe-80cb-4388ad7f6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "year1 = XData[\"j.date\"] <= 365\n",
    "helsinki = (60 <= XData[\"lat\"])&(XData[\"lat\"] <= 60.5)&(24.5 <= XData[\"lon\"])&(XData[\"lon\"] <= 25.5)\n",
    "XData1 = XData[year1]\n",
    "species1 = species[year1]\n",
    "XData1_helsinki = XData[year1&helsinki]\n",
    "species1_helsinki = species[year1&helsinki]\n",
    "\n",
    "print(\"XData in same order as species data:\")\n",
    "print(\"2023:\", (XData1.index==species1.index).all())\n",
    "print(\"2023 in Helsinki:\", (XData1_helsinki.index==species1_helsinki.index).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572be8fa-3e60-4501-9c09-727259113164",
   "metadata": {},
   "source": [
    "Save final training XData to `data_path` and training species data `data_path/spname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f48f72-80a7-4a1f-bbe4-b74b50d76f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"XData.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(XData, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(data_path + \"XData_2023.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(XData1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(data_path + \"XData_2023_helsinki.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(XData1_helsinki, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "sp_lower = sp.lower().replace(\" \", \"_\").split(\".\")[0]\n",
    "sp_dir = data_path + sp_lower + \"/\"\n",
    "with open(sp_dir + sp_lower + \"_prior.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(species, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(sp_dir + sp_lower +\"_2023_prior.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(species1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(sp_dir + sp_lower + \"_2023_helsinki_prior.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(species1_helsinki, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d47b2a-a103-4ac1-a959-597439ab1290",
   "metadata": {},
   "source": [
    "Convert variance map to probability scale instead of linear scale. This is a slow approximation. \n",
    "\n",
    "**@Gleb - I will try to derive a fast and accurate approximation, but failing that we probably need to calculate these with many samples.**\n",
    "\n",
    "GT: for whatever reason this uses only one core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f000518-bcf6-47b9-8ca3-61755e1451ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "m.cdf(torch.tensor(np.arange(10))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7456c23-2130-41db-957a-f600a6f69d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(sp_dir+sp_lower+\"_a.tif\") as src:\n",
    "    a_map = src.read(1) \n",
    "    profile = src.profile\n",
    "    \n",
    "with rasterio.open(sp_dir+sp_lower+\"_vaL.tif\") as src:\n",
    "    vaL_map = src.read(1) \n",
    "vaL_map[(np.isnan(vaL_map))&(~np.isnan(a_map))] = 1.0 # ensure a_map != nan implies va_map != nan\n",
    "vaL_map[np.isnan(a_map)] = np.nan\n",
    "\n",
    "aL_map = scipy_norm.ppf(a_map)\n",
    "idx = ~np.isnan(vaL_map)\n",
    "va_map = np.nan*vaL_map\n",
    "aL_map, vaL_map = aL_map[idx], vaL_map[idx]\n",
    "dn = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "\n",
    "# sharing randomness across cells to save computation\n",
    "# running in loop and using moment formula because broadcasting kept crashing\n",
    "n_mc = 100\n",
    "E_Phi = np.zeros(idx.sum())\n",
    "E_Phi_squared = np.zeros(idx.sum())\n",
    "for _ in tqdm.tqdm(range(n_mc)):\n",
    "    L_sample = aL_map + np.sqrt(vaL_map)*np.random.normal(0, 1)\n",
    "    p_sample = scipy_norm.cdf(L_sample)\n",
    "    p_sample = dn.cdf(torch.tensor(np.arange(10))).numpy()\n",
    "    E_Phi += p_sample\n",
    "    E_Phi_squared += np.square(p_sample)\n",
    "E_Phi /= n_mc\n",
    "E_Phi_squared /= n_mc\n",
    "\n",
    "va_map[idx] = E_Phi_squared - np.square(E_Phi)\n",
    "\n",
    "with rasterio.open(sp_dir + sp_lower + \"_va.tif\", \"w\", **profile) as dst:\n",
    "    dst.write(va_map.astype(np.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2e232-8695-4b71-99ba-d1fb60bebf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vaL_map)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044c666-7dbb-4f79-b8f4-be573acdf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(va_map)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9bf82-f07e-4703-b792-2b3d5edd943c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
